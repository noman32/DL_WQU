{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62b340a",
   "metadata": {},
   "source": [
    "# Linear Regression and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2babd5e",
   "metadata": {},
   "source": [
    "## 1. Linear Models and Linear Regression\n",
    "\n",
    "### 1.1 What is Linear Regression?\n",
    "\n",
    "Linear regression is one of the simplest forms of supervised learning. In its basic form, it models the relationship between input(s) and output by assuming a straight-line relationship:\n",
    "\n",
    "$$\n",
    "\\hat{y} = XW + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $X$ = Input features (tensor)  \n",
    "- $W$ = Weights (parameters to learn)  \n",
    "- $b$ = Bias term  \n",
    "- $\\hat{y}$ = Predicted output\n",
    "\n",
    "### 1.2 Connection to Neural Networks\n",
    "\n",
    "A neural network with no hidden layers and no activation functions behaves exactly like a linear regression model. It computes a weighted sum of inputs plus a bias.\n",
    "\n",
    "> **Key Insight:**  \n",
    "> Linear models are the building blocks of deep learning. If we stack multiple layers and apply activation functions, we move from simple lines to complex, nonlinear functions.\n",
    "\n",
    "### 1.3 Real-World Examples\n",
    "\n",
    "- Predicting house prices based on size  \n",
    "- Estimating salary based on years of experience  \n",
    "- Predicting concrete strength based on material composition (our dataset)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314998e6",
   "metadata": {},
   "source": [
    "## 2. Mathematical Formulation of a Linear Model\n",
    "\n",
    "The prediction formula for a linear model is:\n",
    "\n",
    "$$\n",
    "\\hat{y} = XW + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "| Term       | Meaning                   | Shape                 |\n",
    "|:-----------|:--------------------------|:----------------------|\n",
    "| $X$        | Input features matrix     | $(n, d)$              |\n",
    "| $W$        | Weights vector            | $(d, 1)$              |\n",
    "| $b$        | Bias (scalar or $(n, 1)$) | Scalar or broadcasted |\n",
    "| $\\hat{y}$  | Predicted outputs         | $(n, 1)$              |\n",
    "\n",
    "In words:\n",
    "- Multiply the input features by the weight vector.\n",
    "- Add the bias.\n",
    "- You get the predicted output!\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 Example Calculation\n",
    "\n",
    "Suppose we have 3 data points and 2 features each:\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "W = \\begin{bmatrix}\n",
    "0.5 \\\\\n",
    "1.5\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "b = 2\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\hat{y} = XW + b =\n",
    "\\begin{bmatrix}\n",
    "6 \\\\\n",
    "11 \\\\\n",
    "16\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f09b7",
   "metadata": {},
   "source": [
    "## 3. Predict Function on a Tiny Dataset\n",
    "\n",
    "We now move from theory to a small working example using a toy dataset. We'll define a `predict(X)` function that computes:\n",
    "\n",
    "$$\n",
    "\\hat{y} = XW + b\n",
    "$$\n",
    "\n",
    "Here, $W$ and $b$ are parameters we‚Äôll learn later, but for now we‚Äôll initialize them manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc06950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "tensor([[0.5000],\n",
      "        [1.0000],\n",
      "        [1.5000],\n",
      "        [2.0000]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Tiny toy dataset\n",
    "X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
    "Y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
    "\n",
    "# Randomly initialized weights and bias\n",
    "W = torch.tensor([[0.5]], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "# Predict function\n",
    "def predict(X):\n",
    "    return torch.matmul(X, W) + b\n",
    "\n",
    "# Test prediction\n",
    "y_pred = predict(X)\n",
    "print(\"Predictions:\")\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d15db",
   "metadata": {},
   "source": [
    "## 4. Loss Functions for Regression\n",
    "\n",
    "In supervised learning, we need a way to measure **how good or bad** our model's predictions are compared to the actual targets.  \n",
    "This measurement is done using a **loss function**.\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "\n",
    "The **Mean Squared Error (MSE)** is the most common loss function for **regression** tasks.\n",
    "\n",
    "Mathematically, it is defined as:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_i$ = true target value  \n",
    "- $\\hat{y}_i$ = model prediction  \n",
    "- $n$ = number of examples\n",
    "\n",
    "‚úÖ **In simple terms:**\n",
    "- Take the **difference** between prediction and true value  \n",
    "- **Square** it (to make all differences positive)  \n",
    "- **Average** the result across all data points\n",
    "\n",
    "\n",
    "üîµ **Other Loss Functions (just for awareness)**\n",
    "\n",
    "- **Mean Absolute Error (MAE):** Takes the absolute difference ‚Äî less sensitive to large errors\n",
    "\n",
    "- **Huber Loss:**  A combination of MSE and MAE ‚Äî more robust to outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error (MSE) function\n",
    "def mse_loss(predictions, targets):\n",
    "    return torch.mean((predictions - targets)**2)\n",
    "\n",
    "# Ground truth\n",
    "Y_true = torch.tensor([[2.0], [4.0], [6.0], [8.0]])\n",
    "\n",
    "# Random predictions\n",
    "Y_pred = torch.tensor([[2.5], [3.5], [5.5], [8.5]])\n",
    "\n",
    "# Compute loss\n",
    "loss = mse_loss(Y_pred, Y_true)\n",
    "print(\"MSE Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44ef94",
   "metadata": {},
   "source": [
    "## 5. Preparing the Data and Model\n",
    "\n",
    "Before we can train our model, we need to prepare two things:\n",
    "\n",
    "1. The **data** ‚Äì we must split it into training and testing sets and normalize it.\n",
    "2. The **model parameters** ‚Äì we must initialize the weights and bias for our linear model.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.1 Why Normalize the Data?\n",
    "\n",
    "The features in the Concrete dataset vary widely in scale (e.g., cement can be >500, while superplasticizer can be <5).  \n",
    "These differences can lead to instability in training and large gradients.\n",
    "\n",
    "To avoid this, we **standardize** each input feature:\n",
    "\n",
    "- Mean = 0  \n",
    "- Standard deviation = 1\n",
    "\n",
    "This ensures the model trains smoothly and avoids issues like exploding gradients.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.2 Why Split the Dataset?\n",
    "\n",
    "We want our model to **generalize** to new, unseen data. To test this, we split the dataset into:\n",
    "\n",
    "- **Training Set**: Used to learn the model parameters.\n",
    "- **Test Set**: Used to evaluate model performance on unseen data.\n",
    "\n",
    "A typical split is **80% training, 20% testing**.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.3 Initializing the Model Parameters\n",
    "\n",
    "We initialize:\n",
    "- A **weight vector `W`** with small random values  \n",
    "- A **bias term `b`** set to zero  \n",
    "\n",
    "We also enable **gradient tracking** with `requires_grad=True` so PyTorch can compute updates during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7599ea8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 824\n",
      "Test set size: 206\n",
      "Weight shape: torch.Size([8, 1])\n",
      "Bias shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r\"D:\\OneDrive\\WorldQuant_DeepLearning\\Nomans_Work_DL_WQU\\concrete+compressive+strength\\Concrete_Data.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "inputs = data.iloc[:, :-1].values  # 8 input features\n",
    "targets = data.iloc[:, -1].values.reshape(-1, 1)  # Target column\n",
    "\n",
    "# Normalize input features (standardization)\n",
    "scaler = StandardScaler()\n",
    "inputs_scaled = scaler.fit_transform(inputs)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "inputs_tensor = torch.tensor(inputs_scaled, dtype=torch.float32)\n",
    "targets_tensor = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "# Shuffle and split into training and test sets (80/20)\n",
    "torch.manual_seed(42)\n",
    "n_samples = inputs_tensor.shape[0]\n",
    "indices = torch.randperm(n_samples)\n",
    "split_idx = int(n_samples * 0.8)\n",
    "\n",
    "train_indices = indices[:split_idx]\n",
    "test_indices = indices[split_idx:]\n",
    "\n",
    "X_train = inputs_tensor[train_indices]\n",
    "y_train = targets_tensor[train_indices]\n",
    "X_test = inputs_tensor[test_indices]\n",
    "y_test = targets_tensor[test_indices]\n",
    "\n",
    "# Initialize model parameters\n",
    "num_features = X_train.shape[1]  # Should be 8\n",
    "W = torch.randn((8, 1), requires_grad=True)\n",
    "W.data *= 0.01  # keep it as a leaf, but scale it\n",
    "b = torch.zeros((1,), requires_grad=True)\n",
    "\n",
    "# Print shapes for confirmation\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "print(\"Weight shape:\", W.shape)\n",
    "print(\"Bias shape:\", b.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634c620",
   "metadata": {},
   "source": [
    "## 6. Understanding Parameters in PyTorch\n",
    "\n",
    "In linear regression, the model learns two key parameters:\n",
    "\n",
    "- **Weights (W):** Represent the importance of each input feature\n",
    "- **Bias (b):** Allows the model to shift predictions up or down\n",
    "\n",
    "---\n",
    "\n",
    "### 6.1 What Do the Shapes Mean?\n",
    "\n",
    "Since we are using **8 input features** from the Concrete dataset, the parameter shapes are:\n",
    "\n",
    "| Parameter | Shape     | Description                      |\n",
    "|-----------|-----------|----------------------------------|\n",
    "| `W`       | (8, 1)    | One weight per input feature     |\n",
    "| `b`       | (1,)      | A single scalar bias             |\n",
    "\n",
    "These were initialized earlier as:\n",
    "```python\n",
    "W = torch.randn((8, 1), requires_grad=True) * 0.01\n",
    "b = torch.zeros((1,), requires_grad=True)\n",
    "```\n",
    "\n",
    "### 6.2 Why requires_grad=True?\n",
    "\n",
    "To train the model using gradient descent, PyTorch needs to compute how the loss changes with respect to W and b. This is done using automatic differentiation.\n",
    "\n",
    "By setting:\n",
    "```python\n",
    "requires_grad=True\n",
    "```\n",
    "PyTorch starts tracking operations on these tensors so that we can later call .backward() to compute gradients automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a82d6",
   "metadata": {},
   "source": [
    "## 7. Gradient Descent ‚Äì Conceptual Overview\n",
    "\n",
    "Once we have a model (like our linear regression setup) and a loss function (such as MSE), we need a way to **optimize the model parameters**, denoted by **œï**, to minimize the loss.\n",
    "\n",
    "This is the role of **gradient descent** ‚Äî one of the most fundamental optimization algorithms in machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "### 7.1 Loss Minimization\n",
    "\n",
    "Our goal is to make our model's predictions as close as possible to the true targets.  \n",
    "We measure prediction error using a **loss function**:\n",
    "\n",
    "$$\n",
    "L[\\phi] \\quad \\text{(scalar)}\n",
    "$$\n",
    "\n",
    "This scalar loss gets **smaller** when the model improves.\n",
    "\n",
    "---\n",
    "\n",
    "### 7.2 What Are Gradients?\n",
    "\n",
    "A **gradient** tells us how much a small change in each parameter œï (such as weights or bias) will affect the loss.\n",
    "\n",
    "- The **sign** tells us which direction to move.  \n",
    "- The **magnitude** tells how steep the slope is.\n",
    "\n",
    "We use this information to **move in the direction that reduces loss**.\n",
    "\n",
    "---\n",
    "\n",
    "### 7.3 Gradient Descent Update Rule\n",
    "\n",
    "Each parameter is updated using the gradient of the loss:\n",
    "\n",
    "$$\n",
    "\\phi \\leftarrow \\phi - \\alpha \\cdot \\nabla_\\phi L\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\phi$ = parameter(s) we want to learn  \n",
    "- $\\alpha$ = learning rate (controls step size)  \n",
    "- $\\nabla_\\phi L$ = gradient of the loss with respect to $\\phi$\n",
    "\n",
    "---\n",
    "\n",
    "### 7.4 Choosing a Learning Rate\n",
    "\n",
    "| Learning Rate $\\alpha$ | Effect                          |\n",
    "|------------------------|----------------------------------|\n",
    "| Too small              | Training is slow                 |\n",
    "| Too large              | Can overshoot or diverge         |\n",
    "| Just right             | Steady convergence toward minimum |\n",
    "\n",
    "---\n",
    "\n",
    "### 7.5 Visual Analogy\n",
    "\n",
    "Imagine standing on a mountain trying to reach the lowest valley:\n",
    "\n",
    "- The **gradient** tells you which way is downhill.\n",
    "- The **learning rate** decides how big each step is.\n",
    "- Your goal is to take careful steps downward until you reach the **lowest point** ‚Äî where the **loss is minimized**.\n",
    "\n",
    "---\n",
    "\n",
    "> ‚úÖ In practice: PyTorch computes gradients automatically using `.backward()`  \n",
    "> We apply the gradient descent update manually in our training loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820b6ab",
   "metadata": {},
   "source": [
    "## 8. Training Loop ‚Äì Manual Gradient Descent\n",
    "\n",
    "### 8.1 What Is a Training Loop?\n",
    "\n",
    "Now it's time to **put everything together**:  \n",
    "We‚Äôll manually implement a training loop that gradually updates the model parameters **œï = {W, b}** using **gradient descent**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What Happens During Each Epoch?\n",
    "\n",
    "In every training epoch, we:\n",
    "\n",
    "1. Use the current parameters to **make predictions**.\n",
    "2. Compute the **loss** (e.g., Mean Squared Error).\n",
    "3. Calculate the **gradients** of the loss with respect to œï.\n",
    "4. **Update** œï using gradient descent:\n",
    "   $$\n",
    "   \\phi \\leftarrow \\phi - \\alpha \\cdot \\nabla_\\phi L\n",
    "   $$\n",
    "5. **Reset gradients** to zero before the next step.\n",
    "\n",
    "---\n",
    "\n",
    "During parameter updates, we wrap the code in torch.no_grad() so PyTorch does not track those operations in the computation graph.\n",
    "\n",
    "Over many epochs, this loop should reduce the loss by gradually adjusting W and b to better values.\n",
    "\n",
    "Now let‚Äôs implement this step-by-step in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5634e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 1523.0864\n",
      "Epoch 20: Loss = 1466.9370\n",
      "Epoch 30: Loss = 1413.0427\n",
      "Epoch 40: Loss = 1361.3132\n",
      "Epoch 50: Loss = 1311.6598\n",
      "Epoch 60: Loss = 1263.9987\n",
      "Epoch 70: Loss = 1218.2491\n",
      "Epoch 80: Loss = 1174.3339\n",
      "Epoch 90: Loss = 1132.1782\n",
      "Epoch 100: Loss = 1091.7117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set learning rate and number of training epochs\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass: compute predictions\n",
    "    y_pred = predict(X_train)\n",
    "    loss = mse_loss(y_pred, y_train)\n",
    "\n",
    "    # Backward pass: compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Parameter update step\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "        b -= learning_rate * b.grad\n",
    "\n",
    "    # Reset gradients\n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c1324",
   "metadata": {},
   "source": [
    "## 9. Plotting Training Loss Over Epochs\n",
    "\n",
    "### 9.1 Why Plot Training Loss?\n",
    "\n",
    "During training, it's important to **monitor the loss over time** to understand how well the model is learning.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What Does the Loss Curve Tell Us?\n",
    "\n",
    "- If the loss **decreases smoothly**, your model is learning.\n",
    "- If the loss **oscillates**, **increases**, or **stays flat**, it may indicate issues:\n",
    "  - Learning rate too high or too low\n",
    "  - Poor initialization\n",
    "  - Bugs in the training loop\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Good vs. Bad Behavior\n",
    "\n",
    "| Behavior                     | Interpretation                     |\n",
    "|-----------------------------|-------------------------------------|\n",
    "| Steadily decreasing loss    | ‚úÖ Model is learning properly        |\n",
    "| Increasing or unstable loss | ‚ö†Ô∏è Check learning rate or gradients |\n",
    "| Flat loss                   | ‚ö†Ô∏è Model may be stuck (not learning) |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Goal\n",
    "\n",
    "We will:\n",
    "1. Track loss values during training\n",
    "2. Plot them after training using **matplotlib**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60a7031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 740.3594\n",
      "Epoch 20: Loss = 715.5526\n",
      "Epoch 30: Loss = 691.7347\n",
      "Epoch 40: Loss = 668.8658\n",
      "Epoch 50: Loss = 646.9078\n",
      "Epoch 60: Loss = 625.8241\n",
      "Epoch 70: Loss = 605.5796\n",
      "Epoch 80: Loss = 586.1406\n",
      "Epoch 90: Loss = 567.4748\n",
      "Epoch 100: Loss = 549.5510\n",
      "Epoch 110: Loss = 532.3395\n",
      "Epoch 120: Loss = 515.8117\n",
      "Epoch 130: Loss = 499.9404\n",
      "Epoch 140: Loss = 484.6992\n",
      "Epoch 150: Loss = 470.0626\n",
      "Epoch 160: Loss = 456.0068\n",
      "Epoch 170: Loss = 442.5083\n",
      "Epoch 180: Loss = 429.5450\n",
      "Epoch 190: Loss = 417.0952\n",
      "Epoch 200: Loss = 405.1386\n",
      "Epoch 210: Loss = 393.6553\n",
      "Epoch 220: Loss = 382.6264\n",
      "Epoch 230: Loss = 372.0339\n",
      "Epoch 240: Loss = 361.8603\n",
      "Epoch 250: Loss = 352.0888\n",
      "Epoch 260: Loss = 342.7033\n",
      "Epoch 270: Loss = 333.6886\n",
      "Epoch 280: Loss = 325.0298\n",
      "Epoch 290: Loss = 316.7128\n",
      "Epoch 300: Loss = 308.7237\n",
      "Epoch 310: Loss = 301.0497\n",
      "Epoch 320: Loss = 293.6781\n",
      "Epoch 330: Loss = 286.5969\n",
      "Epoch 340: Loss = 279.7947\n",
      "Epoch 350: Loss = 273.2603\n",
      "Epoch 360: Loss = 266.9829\n",
      "Epoch 370: Loss = 260.9523\n",
      "Epoch 380: Loss = 255.1589\n",
      "Epoch 390: Loss = 249.5931\n",
      "Epoch 400: Loss = 244.2459\n",
      "Epoch 410: Loss = 239.1085\n",
      "Epoch 420: Loss = 234.1728\n",
      "Epoch 430: Loss = 229.4305\n",
      "Epoch 440: Loss = 224.8742\n",
      "Epoch 450: Loss = 220.4964\n",
      "Epoch 460: Loss = 216.2899\n",
      "Epoch 470: Loss = 212.2481\n",
      "Epoch 480: Loss = 208.3644\n",
      "Epoch 490: Loss = 204.6325\n",
      "Epoch 500: Loss = 201.0464\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize list to store loss values\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "learning_rate = 0.001\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_pred = predict(X_train)\n",
    "    loss = mse_loss(y_pred, y_train)\n",
    "    losses.append(loss.item())  # Track the loss\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "        b -= learning_rate * b.grad\n",
    "\n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "# Plot loss curve\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8960dd",
   "metadata": {},
   "source": [
    "‚úÖ This plot helps us understand whether our training procedure is working and whether the learning rate and model parameters are reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3f5a3",
   "metadata": {},
   "source": [
    "## 10. Evaluating Model Performance\n",
    "\n",
    "After training, we evaluate our model on **unseen data** to check how well it generalizes.\n",
    "\n",
    "We use the **test set** for this purpose ‚Äî it was never shown to the model during training.\n",
    "\n",
    "---\n",
    "\n",
    "### 10.1 Why Test the Model?\n",
    "\n",
    "Training loss tells us how well the model fits the training data.  \n",
    "But a model that performs well on the training set might still perform poorly on new data ‚Äî this is called **overfitting**.\n",
    "\n",
    "Evaluating on a separate **test set** gives us an estimate of **true model performance**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Steps for Evaluation:\n",
    "\n",
    "1. Use the final trained model to **predict on `X_test`**\n",
    "2. Compute the **Mean Squared Error** using `mse_loss()`\n",
    "3. Compare it with training loss to detect:\n",
    "   - Underfitting (both losses high)\n",
    "   - Overfitting (train loss low, test loss high)\n",
    "   - Generalization (both reasonably low)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec5afd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 197.5291\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = predict(X_test)\n",
    "\n",
    "# Compute test loss\n",
    "test_loss = mse_loss(y_test_pred, y_test)\n",
    "\n",
    "# Print test loss\n",
    "print(f\"Test Loss: {test_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857190f",
   "metadata": {},
   "source": [
    "> ‚úÖ A small test loss indicates good generalization.  \n",
    "> If the test loss is much higher than the training loss, the model may have overfitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b6d012",
   "metadata": {},
   "source": [
    "## 11. Reflection and Summary\n",
    "\n",
    "We‚Äôve now completed a full walk-through of **manual linear regression using PyTorch**:\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What We Built\n",
    "\n",
    "- A linear model:‚ÄÉ$\\hat{y} = XW + b$\n",
    "- A loss function:‚ÄÉ**Mean Squared Error (MSE)**\n",
    "- A training loop with:\n",
    "  - Gradient computation using `.backward()`\n",
    "  - Parameter updates using gradient descent\n",
    "  - Loss tracking and visualization\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ What We Learned\n",
    "\n",
    "| Concept                   | Insight                                                        |\n",
    "|---------------------------|----------------------------------------------------------------|\n",
    "| Linear Regression         | The foundation of all deep learning models                     |\n",
    "| PyTorch Tensors           | Used to represent inputs, targets, weights, and gradients      |\n",
    "| Gradient Descent          | Optimizes model parameters by minimizing loss                  |\n",
    "| Training/Test Split       | Essential for evaluating generalization                        |\n",
    "| Loss Curve                | Visual tool to monitor learning progress                       |\n",
    "| Evaluation                | Helps detect underfitting, overfitting, or good generalization |\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Why This Matters\n",
    "\n",
    "This notebook builds intuition for **what neural networks are doing under the hood**.  \n",
    "In fact, a neural network with no hidden layers is **just a linear model**.\n",
    "\n",
    "> ‚úÖ Understanding this foundation prepares us for adding **non-linearity**, **hidden layers**, and building full **neural networks** in the next notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### üîú Coming Up Next\n",
    "\n",
    "In the next notebook, we will:\n",
    "- Learn why linear models are **not enough** for most real-world tasks\n",
    "- Introduce **activation functions** (like ReLU)\n",
    "- Build a network with **a hidden layer**\n",
    "\n",
    "We‚Äôre now ready to move **from lines to layers**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
